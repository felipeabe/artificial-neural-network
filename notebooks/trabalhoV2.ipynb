{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felipeabe/artificial-neural-network/blob/feature%2Fentrega-final/notebooks/trabalhoV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6DWBROmLm96",
        "outputId": "dc40bcab-dd29-455a-86da-b0cd132ae743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'artificial-neural-network'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 130 (delta 58), reused 37 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (130/130), 909.92 KiB | 7.16 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n",
            "datasets  notebooks  README.md\tsrc  teste.ipynb\n"
          ]
        }
      ],
      "source": [
        "# Remover o diretório 'artificial-neural-network' se já existir\n",
        "!rm -rf /content/artificial-neural-network\n",
        "\n",
        "# Clonar o repositório do GitHub no ambiente do Colab\n",
        "!git clone --branch feature/entrega-final https://github.com/felipeabe/artificial-neural-network.git\n",
        "\n",
        "# Adicionar o diretório src ao sys.path para permitir a importação de módulos\n",
        "import sys\n",
        "sys.path.append('/content/artificial-neural-network/src')\n",
        "\n",
        "# Verificar se o repositório foi clonado corretamente\n",
        "!ls /content/artificial-neural-network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T-fLx-D1L8VX"
      },
      "outputs": [],
      "source": [
        "# Importando bibliotecas necessárias\n",
        "import pandas as pd\n",
        "\n",
        "# Carregar o dataset 'obesity.csv'\n",
        "# Este conjunto contém dados sobre obesidade com fatores como estilo de vida e transporte\n",
        "dados_obesidade = pd.read_csv(\"/content/artificial-neural-network/datasets/obesity.csv\")\n",
        "\n",
        "# Renomear colunas para nomes mais intuitivos\n",
        "mapear_colunas = {\n",
        "    'family_history_with_overweight': 'historico_familiar',\n",
        "    'FAVC': 'comida_calorica',\n",
        "    'FCVC': 'vegetais',\n",
        "    'NCP': 'refeicoes_dia',\n",
        "    'SMOKE': 'fuma',\n",
        "    'CH2O': 'agua_dia',\n",
        "    'SCC': 'calorias',\n",
        "    'FAF': 'atividade_fisica',\n",
        "    'CALC': 'alcool',\n",
        "    'MTRANS': 'transporte',\n",
        "    'NObeyesdad': 'nivel_obesidade'\n",
        "}\n",
        "dados_obesidade = dados_obesidade.rename(columns=mapear_colunas)\n",
        "\n",
        "# Remover colunas irrelevantes para a análise\n",
        "colunas_remover = ['CAEC', 'TUE']\n",
        "dados_obesidade = dados_obesidade.drop(columns=colunas_remover)\n",
        "\n",
        "# Codificar variáveis categóricas (binárias e escalares)\n",
        "mapeamento_binario = {\n",
        "    'Gender': {\"Female\": 0, \"Male\": 1},\n",
        "    'historico_familiar': {\"yes\": 1, \"no\": 0},\n",
        "    'comida_calorica': {\"yes\": 1, \"no\": 0},\n",
        "    'fuma': {\"yes\": 1, \"no\": 0},\n",
        "    'calorias': {\"yes\": 1, \"no\": 0}\n",
        "}\n",
        "for coluna, mapeamento in mapeamento_binario.items():\n",
        "    dados_obesidade[coluna] = dados_obesidade[coluna].map(mapeamento)\n",
        "\n",
        "# Codificar consumo de álcool e transporte\n",
        "mapeamento_alcool = {'no': 0, 'Sometimes': 1, 'Frequently': 2, 'Always': 3}\n",
        "dados_obesidade['alcool'] = dados_obesidade['alcool'].map(mapeamento_alcool)\n",
        "\n",
        "mapeamento_transporte = {\n",
        "    'Walking': 0, 'Bike': 0,\n",
        "    'Motorbike': 1, 'Automobile': 1,\n",
        "    'Public_Transportation': 1\n",
        "}\n",
        "dados_obesidade['transporte'] = dados_obesidade['transporte'].map(mapeamento_transporte)\n",
        "\n",
        "# Normalizar dados contínuos (altura, peso, idade)\n",
        "colunas_normalizar = ['Height', 'Weight', 'Age']\n",
        "dados_obesidade[colunas_normalizar] = dados_obesidade[colunas_normalizar].apply(\n",
        "    lambda x: ((x - x.min()) / (x.max() - x.min())).round(3)\n",
        ")\n",
        "\n",
        "# Dividir o dataset em treino (80%) e teste (20%)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_obesidade = dados_obesidade.drop(columns=[\"nivel_obesidade\"])\n",
        "y_obesidade = dados_obesidade[\"nivel_obesidade\"]\n",
        "X_treino_multiclasse, X_teste_multiclasse, y_treino_multiclasse, y_teste_multiclasse = train_test_split(\n",
        "    X_obesidade, y_obesidade, test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pChH_5lqR-eP",
        "outputId": "c2cd4080-98b1-43ba-e9a5-f447ced7a2be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-0ed7743b9e9b>:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dados_imoveis = dados_imoveis.replace({True: 1, False: 0})\n"
          ]
        }
      ],
      "source": [
        "# Importar bibliotecas necessárias\n",
        "import pandas as pd\n",
        "\n",
        "# Carregar o dataset 'houses.csv'\n",
        "dados_imoveis = pd.read_csv(\"/content/artificial-neural-network/datasets/houses.csv\")\n",
        "\n",
        "# Remover colunas irrelevantes\n",
        "colunas_remover = ['renovated', 'quartile_zone']\n",
        "dados_imoveis = dados_imoveis.drop(columns=colunas_remover)\n",
        "\n",
        "# Codificar valores booleanos (True/False) em numéricos (1/0)\n",
        "dados_imoveis = dados_imoveis.replace({True: 1, False: 0})\n",
        "\n",
        "# Extrair o ano da coluna de data\n",
        "dados_imoveis['date'] = pd.to_datetime(dados_imoveis['date'])\n",
        "dados_imoveis['ano_construcao'] = dados_imoveis['date'].dt.year\n",
        "dados_imoveis = dados_imoveis.drop(columns=['date'])\n",
        "\n",
        "# Normalizar colunas contínuas ('price' e 'living_in_m2') para valores entre 0 e 1\n",
        "colunas_normalizar = ['price', 'living_in_m2']\n",
        "dados_imoveis[colunas_normalizar] = dados_imoveis[colunas_normalizar].apply(\n",
        "    lambda x: ((x - x.min()) / (x.max() - x.min())).round(3)\n",
        ")\n",
        "\n",
        "# Dividir o conjunto de dados em treino (80%) e teste (20%)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_imoveis = dados_imoveis.drop(columns=[\"price\"])\n",
        "y_imoveis = dados_imoveis[\"price\"]\n",
        "X_treino_regressao, X_teste_regressao, y_treino_regressao, y_teste_regressao = train_test_split(\n",
        "    X_imoveis, y_imoveis, test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eqeegzxe1c7f"
      },
      "outputs": [],
      "source": [
        "# Importar bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Carregar o dataset 'alzheimer.csv'\n",
        "dados_alzheimer = pd.read_csv(\"/content/artificial-neural-network/datasets/alzheimer.csv\")\n",
        "\n",
        "# Remover colunas irrelevantes\n",
        "dados_alzheimer = dados_alzheimer.drop(columns=[\"PatientID\", \"DoctorInCharge\"])\n",
        "\n",
        "# Separar variáveis categóricas e numéricas\n",
        "variaveis_categoricas = [\"Gender\", \"Ethnicity\", \"EducationLevel\"]\n",
        "variaveis_numericas = [col for col in dados_alzheimer.columns if col not in variaveis_categoricas + [\"Diagnosis\"]]\n",
        "\n",
        "# Codificar variáveis categóricas\n",
        "codificador = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
        "categorias_codificadas = codificador.fit_transform(dados_alzheimer[variaveis_categoricas])\n",
        "categorias_codificadas_df = pd.DataFrame(categorias_codificadas, columns=codificador.get_feature_names_out(variaveis_categoricas))\n",
        "\n",
        "# Normalizar variáveis numéricas\n",
        "escalador = StandardScaler()\n",
        "numericas_normalizadas = escalador.fit_transform(dados_alzheimer[variaveis_numericas])\n",
        "numericas_normalizadas_df = pd.DataFrame(numericas_normalizadas, columns=variaveis_numericas)\n",
        "\n",
        "# Combinar dados processados\n",
        "dados_processados = pd.concat([numericas_normalizadas_df, categorias_codificadas_df], axis=1)\n",
        "dados_processados[\"Diagnosis\"] = dados_alzheimer[\"Diagnosis\"]\n",
        "\n",
        "# Dividir os dados em conjuntos de treino e teste\n",
        "X_alzheimer = dados_processados.drop(columns=[\"Diagnosis\"])\n",
        "y_alzheimer = dados_processados[\"Diagnosis\"]\n",
        "X_treino_binario, X_teste_binario, y_treino_binario, y_teste_binario = train_test_split(\n",
        "    X_alzheimer, y_alzheimer, test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eixiUcmFXZcX",
        "outputId": "7b35129f-01f2-4f82-dd6d-779d399b97e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 0/1000, Perda: 0.2501\n",
            "Época 100/1000, Perda: 0.2415\n",
            "Época 200/1000, Perda: 0.2363\n",
            "Época 300/1000, Perda: 0.2332\n",
            "Época 400/1000, Perda: 0.2312\n",
            "Época 500/1000, Perda: 0.2300\n",
            "Época 600/1000, Perda: 0.2292\n",
            "Época 700/1000, Perda: 0.2285\n",
            "Época 800/1000, Perda: 0.2279\n",
            "Época 900/1000, Perda: 0.2272\n",
            "Acurácia do modelo: 64.42%\n"
          ]
        }
      ],
      "source": [
        "# Adicionar o diretório `src` ao caminho do Python\n",
        "# Isso permite que módulos personalizados no diretório src sejam importados diretamente no ambiente Python.\n",
        "import sys\n",
        "sys.path.append('/content/artificial-neural-network/src')\n",
        "\n",
        "# Importar a implementação da Rede Neural\n",
        "# Importa as classes e funções necessárias para a configuração e treinamento do modelo de Rede Neural Artificial.\n",
        "from neural_network import RedeNeural\n",
        "from activations import relu, sigmoid, tanh\n",
        "from losses import mse_loss, cross_entropy_loss\n",
        "\n",
        "# Selecionar o conjunto de dados a ser utilizado no treinamento\n",
        "# Aqui, utilizamos o conjunto de treino e teste processado para a tarefa de classificação binária.\n",
        "# Esta escolha deve ser ajustada dependendo da tarefa: regressão, classificação binária ou multiclasse.\n",
        "X_treino = X_treino_binario\n",
        "y_treino = y_treino_binario\n",
        "X_teste = X_teste_binario\n",
        "y_teste = y_teste_binario\n",
        "\n",
        "# Configuração dos parâmetros da Rede Neural\n",
        "# Estes parâmetros definem a estrutura do modelo e os hiperparâmetros do processo de treinamento:\n",
        "# - `input_size`: número de características de entrada no conjunto de treino.\n",
        "# - `hidden_size`: número de neurônios na camada oculta, influenciando a capacidade do modelo de capturar padrões complexos.\n",
        "# - `output_size`: número de neurônios na camada de saída, ajustado de acordo com a tarefa (binária ou multiclasse).\n",
        "# - `activation`: função de ativação usada para introduzir não-linearidades no modelo.\n",
        "# - `loss`: função de perda para medir o erro durante o treinamento.\n",
        "# - `learning_rate`: taxa de aprendizado que controla o tamanho dos ajustes nos pesos.\n",
        "# - `epochs`: número de iterações completas sobre o conjunto de dados de treino.\n",
        "configuracao = {\n",
        "    \"input_size\": X_treino.shape[1],  # Número de características no conjunto de treino\n",
        "    \"hidden_size\": 10,  # Número de neurônios na camada oculta\n",
        "    \"output_size\": 1,  # Saída com 1 neurônio (para classificação binária)\n",
        "    \"activation\": \"relu\",  # Função de ativação escolhida\n",
        "    \"loss\": \"mse\",  # Função de perda escolhida\n",
        "    \"learning_rate\": 0.01,  # Taxa de aprendizado para o gradiente descendente\n",
        "    \"epochs\": 1000  # Número de épocas de treinamento\n",
        "}\n",
        "\n",
        "# Instanciar a Rede Neural\n",
        "# A classe `RedeNeural` representa uma rede neural de múltiplas camadas com capacidade de realizar propagação para frente,\n",
        "# retropropagação e ajuste dos pesos baseados no gradiente descendente.\n",
        "rede_neural = RedeNeural(\n",
        "    entrada_tamanho=configuracao[\"input_size\"],  # Número de características de entrada\n",
        "    oculta_tamanho=configuracao[\"hidden_size\"],  # Número de neurônios na camada oculta\n",
        "    saida_tamanho=configuracao[\"output_size\"],  # Número de neurônios na camada de saída\n",
        "    ativacao=configuracao[\"activation\"],  # Função de ativação configurada\n",
        "    perda=configuracao[\"loss\"]  # Função de perda configurada\n",
        ")\n",
        "\n",
        "# Treinar a Rede Neural com os dados de treino\n",
        "# O método `treinar` realiza o ajuste dos pesos através do algoritmo de retropropagação,\n",
        "# utilizando a função de ativação e a função de perda configuradas. O treinamento ocorre por várias épocas.\n",
        "rede_neural.treinar(\n",
        "    X_treino.to_numpy(),  # Dados de entrada para treinamento (convertidos para numpy)\n",
        "    y_treino.to_numpy().reshape(-1, 1),  # Rótulos de saída ajustados para o formato adequado\n",
        "    configuracao[\"epochs\"],  # Número de épocas\n",
        "    configuracao[\"learning_rate\"]  # Taxa de aprendizado\n",
        ")\n",
        "\n",
        "# Avaliar a Rede Neural com os dados de teste\n",
        "# Após o treinamento, a avaliação do modelo é realizada utilizando o conjunto de teste.\n",
        "# A acurácia é calculada comparando as predições da rede com os rótulos verdadeiros.\n",
        "y_predito = rede_neural.propagacao_frente(X_teste.to_numpy())  # Propagação para frente no conjunto de teste\n",
        "acuracia = (y_predito.round() == y_teste.to_numpy().reshape(-1, 1)).mean() * 100  # Cálculo da acurácia\n",
        "print(f\"Acurácia do modelo: {acuracia:.2f}%\")  # Exibição da acurácia do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento para Classificação Binária"
      ],
      "metadata": {
        "id": "lvJSJx7nsp3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração para o treino de classificação binária\n",
        "# Este bloco implementa o treinamento para tarefas de classificação binária, como prever duas classes possíveis.\n",
        "# Exemplos: diagnóstico positivo/negativo ou ativado/desativado.\n",
        "\n",
        "# Selecionar o conjunto de dados para classificação binária\n",
        "X_treino = X_treino_binario\n",
        "y_treino = y_treino_binario\n",
        "X_teste = X_teste_binario\n",
        "y_teste = y_teste_binario\n",
        "\n",
        "# Configurar os parâmetros da Rede Neural para classificação binária\n",
        "configuracao_binaria = {\n",
        "    \"input_size\": X_treino.shape[1],  # Número de características (features) de entrada\n",
        "    \"hidden_size\": 10,  # Camada oculta com 10 neurônios para capturar padrões complexos\n",
        "    \"output_size\": 1,  # Uma saída para prever 0 ou 1\n",
        "    \"activation\": \"relu\",  # Função de ativação para introduzir não-linearidade\n",
        "    \"loss\": \"mse\",  # Função de perda para minimizar erros quadráticos médios\n",
        "    \"learning_rate\": 0.01,  # Taxa de aprendizado para ajustes dos pesos\n",
        "    \"epochs\": 1000  # Iterações completas sobre o conjunto de treino\n",
        "}\n",
        "\n",
        "# Instanciar e treinar a Rede Neural\n",
        "rede_neural_binaria = RedeNeural(\n",
        "    entrada_tamanho=configuracao_binaria[\"input_size\"],\n",
        "    oculta_tamanho=configuracao_binaria[\"hidden_size\"],\n",
        "    saida_tamanho=configuracao_binaria[\"output_size\"],\n",
        "    ativacao=configuracao_binaria[\"activation\"],\n",
        "    perda=configuracao_binaria[\"loss\"]\n",
        ")\n",
        "\n",
        "# Treinar a Rede Neural\n",
        "rede_neural_binaria.treinar(\n",
        "    X_treino.to_numpy(),\n",
        "    y_treino.to_numpy().reshape(-1, 1),\n",
        "    configuracao_binaria[\"epochs\"],\n",
        "    configuracao_binaria[\"learning_rate\"]\n",
        ")\n",
        "\n",
        "# Avaliar o modelo no conjunto de teste\n",
        "y_predito_binario = rede_neural_binaria.propagacao_frente(X_teste.to_numpy())\n",
        "acuracia_binaria = (y_predito_binario.round() == y_teste.to_numpy().reshape(-1, 1)).mean() * 100\n",
        "print(f\"Acurácia do modelo (Classificação Binária): {acuracia_binaria:.2f}%\")\n"
      ],
      "metadata": {
        "id": "FQuihHRLqsqy",
        "outputId": "8cbe555d-01a4-465a-c65c-125f4c389f41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 0/1000, Perda: 0.2501\n",
            "Época 100/1000, Perda: 0.2415\n",
            "Época 200/1000, Perda: 0.2363\n",
            "Época 300/1000, Perda: 0.2332\n",
            "Época 400/1000, Perda: 0.2312\n",
            "Época 500/1000, Perda: 0.2300\n",
            "Época 600/1000, Perda: 0.2292\n",
            "Época 700/1000, Perda: 0.2286\n",
            "Época 800/1000, Perda: 0.2281\n",
            "Época 900/1000, Perda: 0.2275\n",
            "Acurácia do modelo (Classificação Binária): 64.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento para Classificação Multiclasse"
      ],
      "metadata": {
        "id": "iF58Y4SFs2Pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração para o treino de classificação multiclasse\n",
        "# Este bloco implementa o treinamento para prever classes múltiplas.\n",
        "# Exemplos: categorias como níveis de obesidade ou diagnósticos diferenciados.\n",
        "\n",
        "# Selecionar o conjunto de dados para classificação multiclasse\n",
        "X_treino = X_treino_multiclasse\n",
        "y_treino = y_treino_multiclasse\n",
        "X_teste = X_teste_multiclasse\n",
        "y_teste = y_teste_multiclasse\n",
        "\n",
        "# Configurar os parâmetros da Rede Neural para classificação multiclasse\n",
        "configuracao_multiclasse = {\n",
        "    \"input_size\": X_treino.shape[1],\n",
        "    \"hidden_size\": 15,  # Camada oculta mais robusta para lidar com mais classes\n",
        "    \"output_size\": len(y_treino.unique()),  # Número de classes diferentes\n",
        "    \"activation\": \"relu\",\n",
        "    \"loss\": \"cross_entropy\",  # Função de perda para tarefas multiclasse\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"epochs\": 1200  # Mais iterações devido à complexidade da tarefa\n",
        "}\n",
        "\n",
        "# Instanciar e treinar a Rede Neural\n",
        "rede_neural_multiclasse = RedeNeural(\n",
        "    entrada_tamanho=configuracao_multiclasse[\"input_size\"],\n",
        "    oculta_tamanho=configuracao_multiclasse[\"hidden_size\"],\n",
        "    saida_tamanho=configuracao_multiclasse[\"output_size\"],\n",
        "    ativacao=configuracao_multiclasse[\"activation\"],\n",
        "    perda=configuracao_multiclasse[\"loss\"]\n",
        ")\n",
        "\n",
        "# Treinar a Rede Neural\n",
        "rede_neural_multiclasse.treinar(\n",
        "    X_treino.to_numpy(),\n",
        "    pd.get_dummies(y_treino).to_numpy(),  # Codificar rótulos como one-hot encoding\n",
        "    configuracao_multiclasse[\"epochs\"],\n",
        "    configuracao_multiclasse[\"learning_rate\"]\n",
        ")\n",
        "\n",
        "# Avaliar o modelo no conjunto de teste\n",
        "y_predito_multiclasse = rede_neural_multiclasse.propagacao_frente(X_teste.to_numpy())\n",
        "acuracia_multiclasse = (y_predito_multiclasse.argmax(axis=1) == y_teste.to_numpy()).mean() * 100\n",
        "print(f\"Acurácia do modelo (Classificação Multiclasse): {acuracia_multiclasse:.2f}%\")\n"
      ],
      "metadata": {
        "id": "m2f0wT9Eq02m",
        "outputId": "0435a907-b396-445b-e58e-d5acff4e6cc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 0/1200, Perda: 0.6929\n",
            "Época 100/1200, Perda: 0.4414\n",
            "Época 200/1200, Perda: 0.4122\n",
            "Época 300/1200, Perda: 0.4120\n",
            "Época 400/1200, Perda: 0.4118\n",
            "Época 500/1200, Perda: 0.4116\n",
            "Época 600/1200, Perda: 0.4114\n",
            "Época 700/1200, Perda: 0.4113\n",
            "Época 800/1200, Perda: 0.4111\n",
            "Época 900/1200, Perda: 0.4109\n",
            "Época 1000/1200, Perda: 0.4107\n",
            "Época 1100/1200, Perda: 0.4105\n",
            "Acurácia do modelo (Classificação Multiclasse): 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento para Regressão"
      ],
      "metadata": {
        "id": "bWLkNZr9tEsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração para o treino de regressão\n",
        "# Este bloco implementa o treinamento para prever valores contínuos.\n",
        "# Exemplos: preço de imóveis, medições físicas ou previsões de métricas.\n",
        "\n",
        "# Selecionar o conjunto de dados para regressão\n",
        "X_treino = X_treino_regressao\n",
        "y_treino = y_treino_regressao\n",
        "X_teste = X_teste_regressao\n",
        "y_teste = y_teste_regressao\n",
        "\n",
        "# Configurar os parâmetros da Rede Neural para regressão\n",
        "configuracao_regressao = {\n",
        "    \"input_size\": X_treino.shape[1],\n",
        "    \"hidden_size\": 8,  # Camada oculta mais simples devido à natureza contínua da saída\n",
        "    \"output_size\": 1,  # Uma saída contínua\n",
        "    \"activation\": \"tanh\",  # Função de ativação para capturar padrões complexos\n",
        "    \"loss\": \"mse\",  # Função de perda para tarefas de regressão\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"epochs\": 800  # Menos iterações devido à simplicidade do problema\n",
        "}\n",
        "\n",
        "# Instanciar e treinar a Rede Neural\n",
        "rede_neural_regressao = RedeNeural(\n",
        "    entrada_tamanho=configuracao_regressao[\"input_size\"],\n",
        "    oculta_tamanho=configuracao_regressao[\"hidden_size\"],\n",
        "    saida_tamanho=configuracao_regressao[\"output_size\"],\n",
        "    ativacao=configuracao_regressao[\"activation\"],\n",
        "    perda=configuracao_regressao[\"loss\"]\n",
        ")\n",
        "\n",
        "# Treinar a Rede Neural\n",
        "rede_neural_regressao.treinar(\n",
        "    X_treino.to_numpy(),\n",
        "    y_treino.to_numpy().reshape(-1, 1),\n",
        "    configuracao_regressao[\"epochs\"],\n",
        "    configuracao_regressao[\"learning_rate\"]\n",
        ")\n",
        "\n",
        "# Avaliar o modelo no conjunto de teste\n",
        "y_predito_regressao = rede_neural_regressao.propagacao_frente(X_teste.to_numpy())\n",
        "erro_medio = ((y_predito_regressao - y_teste.to_numpy().reshape(-1, 1))**2).mean()\n",
        "print(f\"Erro Médio Quadrático (Regressão): {erro_medio:.4f}\")\n"
      ],
      "metadata": {
        "id": "mHOgGYMSrSps",
        "outputId": "bab31000-f7db-4198-f8ad-0dbff4d49235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 0/800, Perda: 0.0569\n",
            "Época 100/800, Perda: 0.0378\n",
            "Época 200/800, Perda: 0.0376\n",
            "Época 300/800, Perda: 0.0376\n",
            "Época 400/800, Perda: 0.0376\n",
            "Época 500/800, Perda: 0.0376\n",
            "Época 600/800, Perda: 0.0376\n",
            "Época 700/800, Perda: 0.0376\n",
            "Erro Médio Quadrático (Regressão): 0.0360\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}